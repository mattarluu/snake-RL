# train_v2.py - Entrenamiento v2 con ajustes m√°s agresivos

import gymnasium as gym
import snake_env
import os
from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import BaseCallback, CheckpointCallback
import numpy as np

class DetailedCallback(BaseCallback):
    """Callback mejorado con m√°s estad√≠sticas"""
    def __init__(self, save_path, check_freq=1000, verbose=1):
        super(DetailedCallback, self).__init__(verbose)
        self.save_path = save_path
        self.check_freq = check_freq
        self.best_mean_score = -np.inf
        self.episode_scores = []
        self.episode_lengths = []
        self.n_episodes_window = 20  # Ventana m√°s grande

    def _init_callback(self):
        os.makedirs(os.path.dirname(self.save_path), exist_ok=True)

    def _on_step(self):
        if self.locals.get("dones", [False])[0]:
            info = self.locals.get('infos', [{}])[0]
            current_score = info.get('score', 0)
            self.episode_scores.append(current_score)
            
            # Calcular media m√≥vil
            if len(self.episode_scores) >= self.n_episodes_window:
                mean_score = np.mean(self.episode_scores[-self.n_episodes_window:])
                
                if mean_score > self.best_mean_score:
                    self.best_mean_score = mean_score
                    if self.verbose > 0:
                        max_score = np.max(self.episode_scores[-self.n_episodes_window:])
                        print(f"\nüåü ¬°Nuevo mejor score medio! Media: {mean_score:.2f}, M√°ximo: {max_score}, Actual: {current_score}")
                    self.model.save(self.save_path)
            
            # Mostrar progreso cada 50 episodios
            if len(self.episode_scores) % 50 == 0:
                recent_mean = np.mean(self.episode_scores[-50:])
                recent_max = np.max(self.episode_scores[-50:])
                print(f"\nüìä √öltimos 50 episodios - Media: {recent_mean:.2f}, M√°ximo: {recent_max}")
        
        return True

# Configuraci√≥n
MODELS_DIR = "models_v2"
LOGS_DIR = "logs_v2"
os.makedirs(MODELS_DIR, exist_ok=True)
os.makedirs(LOGS_DIR, exist_ok=True)

# Hiperpar√°metros V2 - M√°s agresivos para aprendizaje r√°pido
LEARNING_RATE = 5e-4  # Aumentado ligeramente para aprender m√°s r√°pido
N_STEPS = 2048
BATCH_SIZE = 128  # Aumentado para m√°s estabilidad
N_EPOCHS = 10
GAMMA = 0.99
GAE_LAMBDA = 0.95
CLIP_RANGE = 0.2
ENT_COEF = 0.02  # M√°s exploraci√≥n inicial
VF_COEF = 0.5  # A√±adido: Value function coefficient

print("=" * 70)
print("üêç ENTRENAMIENTO V2 - CON MEJOR DETECCI√ìN ESPACIAL")
print("=" * 70)
print("\nMejoras en esta versi√≥n:")
print("  ‚úì Detecci√≥n de peligros mira 3 pasos adelante")
print("  ‚úì Sabe distancia a cada pared")
print("  ‚úì Conoce √°ngulo a la manzana")
print("  ‚úì Mayor exploraci√≥n inicial")
print("  ‚úì Estad√≠sticas de muerte (pared vs cuerpo)")
print("=" * 70 + "\n")

# Callback √∫nico para todas las fases
best_model_callback = DetailedCallback(
    save_path=os.path.join(MODELS_DIR, "best_model_v2.zip"),
    check_freq=1000,
    verbose=1
)

checkpoint_callback = CheckpointCallback(
    save_freq=100000,
    save_path=os.path.join(MODELS_DIR, "checkpoints"),
    name_prefix="snake_v2_checkpoint"
)

# --- FASE 1: Radio F√°cil (Radio 5) ---
print("\n" + "=" * 70)
print("üìç FASE 1: APRENDIZAJE B√ÅSICO (Radio 5)")
print("=" * 70)
print("Objetivo: Aprender a no chocar y comer manzanas cercanas\n")

env_easy = gym.make("Snake-Radius-Easy-v0")

model = PPO(
    "MlpPolicy",
    env_easy,
    learning_rate=LEARNING_RATE,
    n_steps=N_STEPS,
    batch_size=BATCH_SIZE,
    n_epochs=N_EPOCHS,
    gamma=GAMMA,
    gae_lambda=GAE_LAMBDA,
    clip_range=CLIP_RANGE,
    ent_coef=ENT_COEF,
    vf_coef=VF_COEF,
    max_grad_norm=0.5,  # Prevenir gradientes explosivos
    verbose=1,
    tensorboard_log=os.path.join(LOGS_DIR, "tensorboard")
)

print("Entrenando fase f√°cil...")
model.learn(
    total_timesteps=600000,  # Aumentado
    tb_log_name="Phase1_Easy_v2",
    callback=[best_model_callback, checkpoint_callback],
    progress_bar=True
)

model.save(os.path.join(MODELS_DIR, "snake_v2_phase1_easy"))
print("\n‚úÖ Fase 1 completada\n")

# --- FASE 2: Radio Medio (Radio 15) ---
print("=" * 70)
print("üìç FASE 2: GENERALIZACI√ìN (Radio 15)")
print("=" * 70)
print("Objetivo: Manzanas m√°s lejanas y navegaci√≥n compleja\n")

env_medium = gym.make("Snake-Radius-Medium-v0")
model.set_env(env_medium)

# Reducir exploraci√≥n en fase 2
model.ent_coef = 0.01

print("Entrenando fase media...")
model.learn(
    total_timesteps=1000000,  # Aumentado significativamente
    tb_log_name="Phase2_Medium_v2",
    reset_num_timesteps=False,
    callback=[best_model_callback, checkpoint_callback],
    progress_bar=True
)

model.save(os.path.join(MODELS_DIR, "snake_v2_phase2_medium"))
print("\n‚úÖ Fase 2 completada\n")

# --- FASE 3: Radio Completo ---
print("=" * 70)
print("üìç FASE 3: MAESTR√çA (Sin l√≠mite de radio)")
print("=" * 70)
print("Objetivo: Dominar todo el tablero\n")

env_hard = gym.make("Snake-Radius-Hard-v0")
model.set_env(env_hard)

# Exploraci√≥n m√≠nima en fase 3
model.ent_coef = 0.005

print("Entrenamiento final...")
model.learn(
    total_timesteps=2000000,  # Mucho m√°s tiempo en fase dif√≠cil
    tb_log_name="Phase3_Hard_v2",
    reset_num_timesteps=False,
    callback=[best_model_callback, checkpoint_callback],
    progress_bar=True
)

model.save(os.path.join(MODELS_DIR, "snake_v2_final"))
print("\n‚úÖ Fase 3 completada\n")

print("=" * 70)
print("üéâ ¬°ENTRENAMIENTO V2 COMPLETADO!")
print("=" * 70)
print(f"\nüìä RESUMEN:")
print(f"  ‚Ä¢ Total timesteps: 3,600,000")
print(f"  ‚Ä¢ Mejor modelo: {os.path.join(MODELS_DIR, 'best_model_v2.zip')}")
print(f"  ‚Ä¢ Modelo final: {os.path.join(MODELS_DIR, 'snake_v2_final.zip')}")
print(f"\nüîç Para ver estad√≠sticas:")
print(f"  tensorboard --logdir {LOGS_DIR}/tensorboard")
print(f"\nüéÆ Para evaluar:")
print(f"  python evaluation_v2.py")
print("=" * 70 + "\n")